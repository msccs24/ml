import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt

df = pd.read_csv("diabetes.csv")
print(df.head(10))
print(df.describe())
df.info()

X = df.drop('Outcome',axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
#Bagging 
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)
print(rf_accuracy)

#Boosting 
ada_model = AdaBoostClassifier(random_state=42)
ada_model.fit(X_train, y_train)
ada_pred = ada_model.predict(X_test)
ada_accuracy = accuracy_score(y_test, ada_pred)
print(ada_accuracy)

#Voting
log_model = LogisticRegression(max_iter = 1000, random_state = 42)
dt_model = DecisionTreeClassifier(random_state = 42)
voting = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('ada', ada_model),
    ('log', log_model),
    ('dt', dt_model)],
    voting='hard')
voting.fit(X_train,y_train)
voting_pred = voting.predict(X_test)
voting_accuracy = accuracy_score(y_test, voting_pred)
print(voting_accuracy)

stack = StackingClassifier(estimators=[
    ('rf', rf_model),
    ('ada', ada_model),
    ('log', log_model)],
    final_estimator=LogisticRegression())
stack.fit(X_train,y_train)
stack_pred = stack.predict(X_test)
stack_accuracy = accuracy_score(y_test, stack_pred)
print(stack_accuracy)

result = {
    'RandomForest': rf_accuracy,
    'AdaBoost': ada_accuracy,
    'Voting': voting_accuracy,
    'Stacking': stack_accuracy
}

plt.bar(result.keys(), result.values())
plt.ylabel("Accuracy")
plt.title("Ensemble Method Comparison")
plt.ylim(0,1)
plt.show()

for method, accuracy in result.items():
    print(f"{method}: {accuracy:.4f} ")

Q2
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import LabelEncoder

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df['species'] = iris.target_names[iris.target]
print("Original Dataset with Categorical Species:\n")
print(df.head())

label_encoder = LabelEncoder()
df['species_encoded'] = label_encoder.fit_transform(df['species'])

print("\nAfter Encoding Categorical Values:\n")
print(df.head())

plt.scatter(df['sepal length (cm)'], df['petal length (cm)'], 
            c=df['species_encoded'])
plt.title("Scatter Plot - Iris Dataset")
plt.xlabel("Sepal Length (cm)")
plt.ylabel("Petal Length (cm)")
plt.grid(True)
plt.show()
