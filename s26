import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv(r"ML\diabetes.csv")
print(df.head(5))
df.info()
print(df.describe())

X = df.drop('Outcome', axis=1)   
y = df['Outcome']                

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

accuracy_scores = []
k_values = range(1, 21)   

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    y_pred = knn.predict(X_test_scaled)
    acc = accuracy_score(y_test, y_pred)
    accuracy_scores.append(acc)

plt.plot(k_values, accuracy_scores, marker='o')
plt.title("K Value vs Accuracy")
plt.xlabel("Number of Neighbors (K)")
plt.ylabel("Accuracy")
plt.grid(True)
plt.show()

best_k = k_values[np.argmax(accuracy_scores)]
print(f"\nBest K value: {best_k}")
print(f"Best accuracy: {max(accuracy_scores):.2f}")
Confusion_Matrix = confusion_matrix(y_test,y_pred)
print("Confusion Matrix :\n",Confusion_Matrix)
#Classification
print("Classification report:\n",classification_report(y_test,y_pred))

plt.figure(figsize=(6, 5)) # Adjust figure size as needed
sns.heatmap(Confusion_Matrix, annot=True, fmt='d', cmap='Blues', cbar=False,xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix Heatmap')
plt.legend()
plt.show()

plt.figure(figsize=(10,6))
sns.barplot(x=list(k_values), y=accuracy_scores, palette="viridis")
plt.title("K Value vs Accuracy (KNN Model)", fontsize=14)
plt.xlabel("Number of Neighbors (K)")
plt.ylabel("Accuracy Score")
plt.xticks(k_values)
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.show()


knn_final = KNeighborsClassifier(n_neighbors=best_k)
knn_final.fit(X_train_scaled, y_train)

y_pred_final = knn_final.predict(X_test_scaled)
print(f"\nModel accuracy on test data: {accuracy_score(y_test, y_pred_final):.2f}")

new_patient = np.array([[2, 120, 70, 20, 79, 25.0, 0.351, 29]])
new_patient_scaled = scaler.transform(new_patient)
prediction = knn_final.predict(new_patient_scaled)

if prediction[0] == 1:
    print("\nThe new patient is DIABETIC (1)")
else:
    print("\nThe new patient is NOT DIABETIC (0)")

Q2
import pandas as pd
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import apriori, association_rules

dataset = []
with open(r"ML\groceries.csv") as f:
    for line in f:
        items = line.strip().split(',')
        dataset.append(items)

print("Sample transactions:")
for t in dataset[:5]:
    print(t)

te = TransactionEncoder()
te_ary = te.fit(dataset).transform(dataset)
df = pd.DataFrame(te_ary, columns=te.columns_)

df = df.fillna(False)
df = df.astype(bool)

print("\n Encoded DataFrame:")
print(df.head())

frequent_itemsets = apriori(df, min_support=0.25, use_colnames=True)

print("\nFrequent Itemsets (Support â‰¥ 0.25):")
print(frequent_itemsets)

rules = association_rules(frequent_itemsets, metric="lift", min_threshold=1)
print("\n Association Rules:")
print(rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])
