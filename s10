import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

iris = load_iris()
X = iris.data          
y = iris.target
t_names = iris.target_names
f_names = iris.feature_names

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_std = scaler.fit_transform(X_train)
X_test_std = scaler.transform(X_test)

pca = PCA()

X_train_pca = pca.fit_transform(X_train_std)
X_test_pca = pca.transform(X_test_std)

print(f"\nPCA explained_variance_ratio : {pca.explained_variance_ratio_}")

cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)
print(f"\nPCA cumulative_variance ratio :",cumulative_variance_ratio)

#var = 0.99
#var = 0.95
var = 0.90
#var = 0.80
#var = 0.50
n_c = np.argmax(cumulative_variance_ratio >= var) + 1

#print(f"\nFor the given variance: {var} \n Number of components :{n_components}")

pca = PCA(n_components = n_c)
X_train_pca = pca.fit_transform(X_train_std)
X_test_pca = pca.transform(X_test_std)

print("\n Original Training Data Shape : ",X_train.shape)
print("\n Reduced Dimentiality after applying PCA : ",X_train_pca.shape)
print(f"\n Total explained variance by selected components : {np.sum(pca.explained_variance_ratio_):.2f}")

L_model = LogisticRegression(random_state = 0)
L_model.fit(X_train_pca, y_train)
y_pred = L_model.predict(X_test_pca)
print(f"\n Model accuracy on test set : {accuracy_score(y_test, y_pred):.2f}")

new_flower1_measurements = np.array([[5.1,3.5,1.4,0.2]])
new_flower1_scaled = scaler.transform(new_flower1_measurements)
new_flower1_pca = pca.transform(new_flower1_scaled)

prediction = L_model.predict(new_flower1_pca)
predicted_species = t_names[prediction[0]]
print(f"\n New flower 1 measurements : {new_flower1_measurements}")
print(f"\n Prediction species : {predicted_species}")

new_flower2_measurements = np.array([[6.2, 2.2, 4.5, 1.5]])
new_flower2_scaled = scaler.transform(new_flower2_measurements)
new_flower2_pca = pca.transform(new_flower2_scaled)

prediction = L_model.predict(new_flower2_pca)
predicted_species = t_names[prediction[0]]
print(f"\n New flower 2 measurements : {new_flower2_measurements}")
print(f"\n Prediction species : {predicted_species}")


Q2
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import LabelEncoder

iris = load_iris()
df = pd.DataFrame(iris.data, columns=iris.feature_names)
df["species"] = iris.target_names[iris.target]

print("Original dataset with categorical values:")
print(df.head())

le = LabelEncoder()
df["species_num"] = le.fit_transform(df["species"])

print("\nAfter converting species to numeric:")
print(df.head())

plt.scatter(df["sepal length (cm)"], df["petal length (cm)"], 
            c=df["species_num"])
plt.xlabel("Sepal Length (cm)")
plt.ylabel("Petal Length (cm)")
plt.title("Scatter Plot - Iris Dataset")
plt.grid(True)
plt.show()
