import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, auc
import matplotlib.pyplot as plt

df = pd.read_csv("diabetes.csv")
print(df.head(10))
print(df.describe())
df.info()

X = df.drop('Outcome',axis=1)
y = df['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Bagging 
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)
rf_accuracy = accuracy_score(y_test, rf_pred)
print(rf_accuracy)

#Boosting 
ada_model = AdaBoostClassifier(random_state=42)
ada_model.fit(X_train, y_train)
ada_pred = ada_model.predict(X_test)
ada_accuracy = accuracy_score(y_test, ada_pred)
print(ada_accuracy)

#Voting

log_model = LogisticRegression(max_iter = 1000, random_state = 42)
dt_model = DecisionTreeClassifier(random_state = 42)

voting = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('ada', ada_model),
    ('log', log_model),
    ('dt', dt_model)],
    voting='hard')

voting.fit(X_train,y_train)
voting_pred = voting.predict(X_test)
voting_accuracy = accuracy_score(y_test, voting_pred)
print(voting_accuracy)

stack = StackingClassifier(estimators=[
    ('rf', rf_model),
    ('ada', ada_model),
    ('log', log_model)],
    final_estimator=LogisticRegression())

stack.fit(X_train,y_train)
stack_pred = stack.predict(X_test)
stack_accuracy = accuracy_score(y_test, stack_pred)
print(stack_accuracy)

result = {
    'RandomForest': rf_accuracy,
    'AdaBoost': ada_accuracy,
    'Voting': voting_accuracy,
    'Stacking': stack_accuracy
}

plt.bar(result.keys(), result.values())
plt.ylabel("Accuracy")
plt.title("Ensemble Method Comparison")
plt.ylim(0,1)
plt.show()

for method, accuracy in result.items():
    print(f"{method}: {accuracy:.4f} ")

Q2
import pandas as pd
import numpy as np          
import math
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv(r"ML\minihomeprices.csv")
print(df)

print("Info:",df.info())

med = df['bedrooms'].median()
print(med)

df['bedrooms'] = df['bedrooms'].fillna(med)
print("Replace Missing value by median and modified in daa set")
print(df)

print("Visualization of data set by combined feature:")
sns.pairplot(df,x_vars = ['area','bedrooms','age'],y_vars=['price'],kind='reg')
plt.show()

print("Visualization of data set by Individual feature:")
sns.lmplot(x="area",y='price',data=df)
plt.show()
sns.lmplot(x="bedrooms",y='price',data=df)
plt.show()
sns.lmplot(x="age",y='price',data=df)
plt.show()

print("Prediction")
X = df[['area','bedrooms','age']]
print(X)

print("Target:")
Y = df['price']
print(Y)

X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size = 0.3,random_state=42)
mlr_model = LinearRegression()
mlr_model.fit(X_train,y_train)
y_pred = mlr_model.predict(X_test)
print("ypred",y_pred)
print("y_test",y_test)
print("Coefficient m1 for Area {}, m2 for Bedrroms {}, m3 for Age {}",mlr_model.coef_)

print("Intercept: ",mlr_model.intercept_)

comparision = pd.DataFrame({'Actual_Price:':y_test,'Predicted_Price':y_pred})
print(comparision)

#evaluation
mse = mean_squared_error(y_test,y_pred)
print("Mean Squared Error: ",mse)

rmse = math.sqrt(mse) 
print("Root Mean Squared Error: ",rmse)

mae = mean_absolute_error(y_test,y_pred)
print("Mean Absolute Error: ",mae)

r_squared = r2_score(y_test,y_pred)
print("R-squared Error: ",r_squared)

score = mlr_model.score(X_test, y_pred)
print(f"R^2 score:{score*100:.2f}% ")

y_pred = mlr_model.predict([[4000,2,10]])
print("Predict for 4000,2,10 :",y_pred)

y_pred = mlr_model.predict([[3000,4,5]])
print("Predict for 3000,4,5 :",y_pred)

y_pred = mlr_model.predict([[2500,2,3]])
print("Predict for 2500,2,3 :",y_pred)
