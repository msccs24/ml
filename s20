import pandas as pd
import math 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.discriminant_analysis import StandardScaler
from sklearn.linear_model import RidgeCV,Lasso, ElasticNet
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv(r'ML\housing.csv')
print(df)

print("\nBoston House Description : ")
print(df.describe())

print("\nBoston House Info : ")
print(df.info())

X= df.drop(['MEDV'], axis=1, inplace=False)
print(X)

y = df['MEDV']
print(y)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print("\nRidge Regression :")
RCV = RidgeCV(alphas=[0.01, 0.1, 1.0], cv=5)
RCV.fit(X_train_scaled, y_train)
y_pred = RCV.predict(X_test_scaled)

cff = RCV.coef_
print("\nCoefficient :  ", cff)
print("RM Coefficient :  ", RCV.coef_[0])
print("LSTAT Coefficient :  ", RCV.coef_[1])
print("PTRAIO Coefficient :  ", RCV.coef_[2])

mse = mean_squared_error(y_test, y_pred)
rmse = math.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)

print(f"\nMean Squared Error (MSE):", mse)
print(f"Root Mean Squared Error (RMSE):", rmse)
print(f"Mean Absolute Error (MAE):", mae)
print(f"R-squared (R²):", r_squared)

positions = [0, 1, 2]

plt.plot(positions, cff[:3], color='red')
plt.xticks(positions, ['RM','LSTAT','PTRATIO'], rotation=45)
plt.ylabel('Coefficient Value')
plt.title('RidgeCV Coefficients for Selected Features')
plt.grid(True)
plt.show()

print("Lasso Regression :")
lasso = Lasso(alpha=0.1)
lasso.fit(X_train_scaled, y_train)
lasso_pred = lasso.predict(X_test_scaled)

cff = lasso.coef_
print("\nCoefficient :  ", cff)
# Coefficient :   [ 58790.23582656 -75604.30368367 -42110.80691333]
print("RM Coefficient :  ", lasso.coef_[0])
# RM Coefficient :   58790.235826558266
print("LSTAT Coefficient :  ", lasso.coef_[1])
# LSTAT Coefficient :   -75604.30368367163
print("PTRAIO Coefficient :  ", lasso.coef_[2])
# PTRAIO Coefficient :   -42110.806913332366


mse = mean_squared_error(y_test, y_pred)
rmse = math.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r_squared = r2_score(y_test, y_pred)

print(f"\nMean Squared Error (MSE):", mse)
# Mean Squared Error (MSE): 6791929101.1434965
print(f"Root Mean Squared Error (RMSE):", rmse)
# Root Mean Squared Error (RMSE): 82413.1609704633
print(f"Mean Absolute Error (MAE):", mae)
# Mean Absolute Error (MAE): 64275.57573633977
print(f"R-squared (R²):", r_squared)
# R-squared (R²): 0.6909612866153836
           
positions = [0, 1, 2]

plt.plot(positions, cff[:3], color='red')
plt.xticks(positions, ['RM','LSTAT','PTRATIO'], rotation=45)
plt.ylabel('Coefficient Value')
plt.title('Lasso Coefficients for Selected Features')
plt.grid(True)
plt.show()

plt.figure(figsize=(10, 6))
X_line = np.linspace(X['RM'].min(), X['RM'].max(), 100).reshape(-1, 1)
LSTAT_mean = np.full_like(X_line, X['LSTAT'].mean())
PTRATIO_mean = np.full_like(X_line, X['PTRATIO'].mean())
X_line_full = np.hstack([X_line, LSTAT_mean, PTRATIO_mean])
X_line_full_scaled = scaler.transform(X_line_full)

ridge_pred = RCV.predict(X_line_full_scaled)
lasso_pred = lasso.predict(X_line_full_scaled)

plt.plot(X_line, ridge_pred, color='blue', label='Ridge Regression')
plt.plot(X_line, lasso_pred, color='red', label='Lasso Regression')
plt.title('Comparison of Ridge, Lasso, and ElasticNet Regression on Boston Housing Data')
plt.xlabel('Average Number of Rooms (RM)')
plt.ylabel('Median Value of Homes (Price)')
plt.legend()
plt.grid(True)
plt.show()

RM_value = 5
LSTAT_value = X['LSTAT'].mean()
PTRATIO_value = X['PTRATIO'].mean()

new_house = np.array([[RM_value, LSTAT_value, PTRATIO_value]])
new_house_scaled = scaler.transform(new_house)

ridge_price = RCV.predict(new_house_scaled)[0]
lasso_price = lasso.predict(new_house_scaled)[0]]

print("\nPredicted Median Home Value for a House with 5 Rooms:")
print(f" Ridge Regression Prediction     : ${ridge_price:,.2f}")
print(f" Lasso Regression Prediction     : ${lasso_price:,.2f}")

Q2

import pandas as pd
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import accuracy_score

data = {
    "Outlook": ["Sunny","Sunny","Overcast","Rain","Rain","Rain","Overcast","Sunny","Sunny","Rain","Sunny","Overcast","Overcast","Rain"],
    "Temperature": ["Hot","Hot","Hot","Mild","Cool","Cool","Cool","Mild","Cool","Mild","Mild","Mild","Hot","Mild"],
    "Humidity": ["High","High","High","High","Normal","Normal","Normal","High","Normal","Normal","Normal","High","Normal","High"],
    "Windy": ["False","True","False","False","False","True","True","False","False","False","True","True","False","True"],
    "Play": ["No","No","Yes","Yes","Yes","No","Yes","No","Yes","Yes","Yes","Yes","Yes","No"]
}

df = pd.DataFrame(data)

le = LabelEncoder()
for col in df.columns:
    df[col] = le.fit_transform(df[col])

X = df.drop("Play", axis=1)
y = df["Play"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train Decision Tree
clf = DecisionTreeClassifier(criterion='entropy', random_state=42)
clf.fit(X_train, y_train)

y_pred = clf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))

print("\nPredicted:", y_pred)
print("Actual:   ", y_test.values)

feature_names = list(X.columns)
tree_rules = export_text(clf, feature_names=feature_names)
print("\nDecision Tree rules:\n")
print(tree_rules)
